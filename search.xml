<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>基于AM-CNN的细菌图谱分类模型</title>
    <url>/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="1-实现过程"><a href="#1-实现过程" class="headerlink" title="1.实现过程"></a>1.实现过程</h1><h2 id="1-1模型选择"><a href="#1-1模型选择" class="headerlink" title="1.1模型选择"></a>1.1模型选择</h2><h3 id="1-1-1基于注意力改进的卷积神经网络算法（AM-CNN）"><a href="#1-1-1基于注意力改进的卷积神经网络算法（AM-CNN）" class="headerlink" title="1.1.1基于注意力改进的卷积神经网络算法（AM-CNN）"></a>1.1.1基于注意力改进的卷积神经网络算法（AM-CNN）</h3><p>​	AM-CNN（基于注意力改进的卷积神经网络）模型是一种用于处理细菌拉曼图谱数据的新型深度学习算法。该模型在输入数据特征组合时，考虑了细菌拉曼图谱的波长向量和强度向量，通过滑动窗口方式获取目标词与周围词的综合向量。首先，通过第一次的注意力机制捕获实体与序列中每个词的相关性，并将其与输入的综合词向量矩阵相乘。接着，对卷积结果使用第二次注意力机制捕获视窗与关系的相关性。最终，将卷积结果与相关性矩阵相乘，得到最后的输出结果。</p>
<p>​	（这个模型的核心在于将细菌拉曼图谱的波长向量和强度向量与输入数据进行组合。首先，将这两种向量进行拼接，构成了最初的输入向量。接着，使用滑动窗口的方式将目标词与周围词组合在一起，形成综合向量。第一次的注意力机制应用在实体与序列中每个词的相关性。将相关性矩阵与输入的综合词向量矩阵相乘，得到一个二维矩阵。然后，使用卷积提取特征，并对卷积结果使用第二次注意力机制捕获视窗与关系的相关性。最后，将卷积结果与相关性矩阵相乘，得到最终的输出结果。通过这种方式，模型能够充分考虑细菌拉曼图谱的波长向量和强度向量在输入数据中的关联关系。）</p>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/image-20230801094141414.png" alt="image-20230801094141414"></p>
<p>​																			模型结构</p>
<p>网络构建：</p>
<ol>
<li>输入层：将细菌拉曼图谱的波长向量和强度向量作为输入数据。波长向量和强度向量可以分别作为两个输入通道。</li>
<li>注意力机制1：使用注意力机制1捕获输入数据中实体与序列中每个词的相关性。可以采用自注意力（self-attention）机制或全局平均池化（global average pooling）等方式。</li>
<li>综合词向量矩阵：将注意力机制1得到的相关性矩阵与输入的综合词向量矩阵相乘，得到一个二维矩阵，用于提取特征。</li>
<li>卷积层：使用卷积层对综合词向量矩阵进行特征提取，可以使用不同的卷积核大小和数量，以捕获不同尺度的特征。</li>
<li>注意力机制2：使用注意力机制2对卷积结果进行进一步的特征选择，捕获视窗与关系的相关性。</li>
<li>全连接层：将经过注意力机制2的卷积结果展平，并通过全连接层进行特征融合和映射，得到最终的输出。</li>
<li>输出层：根据任务需求，可以添加合适的输出层，如softmax层用于分类任务，sigmoid层用于二分类任务等。</li>
<li>损失函数：选择合适的损失函数用于模型的训练和优化。</li>
</ol>
<p>​	</p>
<p>​	我们在训练网络时，为了使得模型可以更快更准确的训练，加入了学习率的自适应调整函数，可以根据训练的数据情况以及已有的训练量来自动调整学习率，使训练效果达到最优。</p>
<p>具体模型构架如下：	</p>
<ol>
<li>我们首先将训练数据集按照4：1划分成训练集与验证集。</li>
<li>构建AM-CNN网络框架</li>
<li>将训练数据输入AM-CNN网络进行1000轮训练</li>
<li>待模型训练好后，使用测试数据测试模型预测结果</li>
<li>调整模型参数，待模型结构最优后，测试模型最终的分类准确度，并记录训练期间 Loss 值的变动情况。</li>
</ol>
<h2 id="1-2基于注意力改进的卷积神经网络（AM-CNN）实验结果"><a href="#1-2基于注意力改进的卷积神经网络（AM-CNN）实验结果" class="headerlink" title="1.2基于注意力改进的卷积神经网络（AM-CNN）实验结果"></a>1.2基于注意力改进的卷积神经网络（AM-CNN）实验结果</h2><p>训练结束后，本实验分别随机选取了3种细菌的50个拉曼数据进行模型评估。</p>
<h3 id="1-2-1未标注数据混合"><a href="#1-2-1未标注数据混合" class="headerlink" title="1.2.1未标注数据混合"></a>1.2.1未标注数据混合</h3><h3 id="1-2-2标注数据混合（6种细菌训练与分类效果）"><a href="#1-2-2标注数据混合（6种细菌训练与分类效果）" class="headerlink" title="1.2.2标注数据混合（6种细菌训练与分类效果）"></a>1.2.2标注数据混合（6种细菌训练与分类效果）</h3><h5 id="1-训练准确率变化情况"><a href="#1-训练准确率变化情况" class="headerlink" title="1.训练准确率变化情况"></a>1.训练准确率变化情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/%E8%AE%AD%E7%BB%83%E5%87%86%E7%A1%AE%E7%8E%87+%E8%AF%84%E4%BC%B0%E5%87%86%E7%A1%AE%E7%8E%87.png" alt="训练准确率+评估准确率"></p>
<p>准确率变化较为理想，满足预期要求!</p>
<ul>
<li>在第38次训练后模型的<strong>训练准确率</strong>维持在98%</li>
<li>在第38次训练后模型的<strong>验证准确率</strong>维持在95%</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">模型验证通常是在训练过程中使用一个独立于训练集和测试集的数据集进行模型性能评估。它可以用来检测模型是否过拟合或者欠拟合。如果模型在训练集上表现良好，但在验证集上表现较差，那就意味着模型可能过拟合了。这种情况下，可以采取一些方法如提前停止训练或增加正则化等来防止模型过拟合。</span><br><span class="line"></span><br><span class="line">训练准确率代表模型在当前训练数据上的表现。训练多轮后，训练准确率会逐渐提高，这表明模型学到了更多的数据分类特征。但是，如果训练准确率开始变得非常高，而验证准确率却不再提高，这说明模型开始过拟合训练数据。</span><br></pre></td></tr></table></figure>

<h5 id="2-训练LOSS值变化情况"><a href="#2-训练LOSS值变化情况" class="headerlink" title="2.训练LOSS值变化情况"></a>2.训练LOSS值变化情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/1LOSS.png" alt="1LOSS"></p>
<h5 id="模型分别对于n种细菌数据各自分类情况"><a href="#模型分别对于n种细菌数据各自分类情况" class="headerlink" title="模型分别对于n种细菌数据各自分类情况"></a>模型分别对于n种细菌数据各自分类情况</h5><p><img src="/2023/10/06/%EF%BF%BD%EF%BF%BDAM-CNN%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD1%06%7B!%EF%BF%BD/98.833%25%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%06%7B%C5%B5Process.png" alt="98.833%四种细菌分类情况Process"></p>
<h5 id=""><a href="#" class="headerlink" title=""></a><img src="/2023/10/06/%EF%BF%BD%EF%BF%BDAM-CNN%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD1%06%7B!%EF%BF%BD/98.75%25%06%7B%C5%B5process.png" alt="98.75%分类情况process"></h5><p><strong>（1）.未标注</strong></p>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/FREE.png" alt="FREE"></p>
<p><strong>（2）.标注</strong></p>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/LABEL.png" alt="LABEL"></p>
<h5 id="5-模型对于测试集的验证情况"><a href="#5-模型对于测试集的验证情况" class="headerlink" title="5.模型对于测试集的验证情况"></a>5.模型对于测试集的验证情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/all_bacteria_heatmap.png" alt="all_bacteria_heatmap"></p>
<h5 id="6-模型六种细菌的ROC变化情况"><a href="#6-模型六种细菌的ROC变化情况" class="headerlink" title="6.模型六种细菌的ROC变化情况"></a>6.模型六种细菌的ROC变化情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/ROC.png" alt="ROC"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ROC曲线可以帮助我们了解分类器在不同阈值下的表现情况，以及在不同的分类阈值下分类器的敏感性和特异性。曲线的横坐标是假正率（False Positive Rate）即被错误地分为正类的样本占所有负样本的比例，曲线的纵坐标是真正率（True Positive Rate）即被正确地分为正类的样本占所有正样本的比例，曲线越接近左上角，说明分类器的表现越好。    通过ROC曲线我们可以判断分类器的性能是否足够好，同时也可以比较多个分类器的性能，选出最佳的分类器。    举个例子如果ROC曲线下的面积（AUC）接近于1，则说明分类器的性能较好，如果ROC曲线下的面积接近于0.5，则说明分类器的性能不如随机猜测（随机猜测的AUC为0.5）。</span><br></pre></td></tr></table></figure>

<p><img src="C:/Users/m/Desktop/新建文件夹/PR.png" alt="PR"></p>
<h3 id="1-2-3与经典网络相比的准确率提升程度"><a href="#1-2-3与经典网络相比的准确率提升程度" class="headerlink" title="1.2.3与经典网络相比的准确率提升程度"></a>1.2.3与经典网络相比的准确率提升程度</h3><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/compare-169657254906614.png" alt="compare"></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>未标注</th>
<th>标注</th>
</tr>
</thead>
<tbody><tr>
<td>ITQ</td>
<td>0.615</td>
<td>0.628</td>
</tr>
<tr>
<td>SH</td>
<td>0.684</td>
<td>0.744</td>
</tr>
<tr>
<td>DSH</td>
<td>0.765</td>
<td>0.780</td>
</tr>
<tr>
<td>SpH</td>
<td>0.795</td>
<td>0.815</td>
</tr>
<tr>
<td>BGAN</td>
<td>0.847</td>
<td>0.913</td>
</tr>
<tr>
<td>AM-CNN</td>
<td>0.954</td>
<td>0.978</td>
</tr>
</tbody></table>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/performence-169657256481017.png" alt="performence"></p>
<h2 id="2-创新点"><a href="#2-创新点" class="headerlink" title="2.创新点"></a>2.创新点</h2><p>关于基于细菌拉曼光谱和注意力机制的CNN网络的创新性内容，具有以下几个主要优势：</p>
<p>1.<strong>引入注意力机制</strong>：</p>
<p>传统的卷积神经网络在图像分类任务中，通常使用池化层、全局卷积核等方式提取图像特征。而引入了注意力机制之后，可以使网络更加关注细菌图像的重要特征，从而提高分类精度。</p>
<p>注意力机制在网络中加入一个注意力模块，用于选择和强调输入光谱数据中的重要信息。在该网络中，注意力机制可以结合不同的损失函数进行优化，从而使网络更加有效地学习到重要特征，提高分类的效果。</p>
<p>2.<strong>应用自适应阈值策略</strong>：</p>
<p>传统的细菌分类算法基于训练集的特征设定分类阈值，在测试集上运用时分类效果可能会有所下降。而基于细菌拉曼光谱和注意力机制的CNN网络，可以采用自适应阈值策略，实现对数据特征的自适应调整，避免了传统算法阈值设定不准确的问题。</p>
<p>该网络中引入自适应阈值参数，在网络训练时动态更新自适应阈值<strong>参数</strong>，通过不断的反馈训练数据的特征，不断地调整自适应阈值参数，避免了传统算法阈值设定不准确的问题。</p>
<p>3.<strong>优化模型参数：</strong></p>
<p>优化模型参数可以提高网络的训练速度和泛化能力，进而提高分类精度。在基于细菌拉曼光谱和注意力机制的CNN网络中，可以通过改变层数、添加跨层连接等方式优化模型的参数，提高分类的效果。</p>
<p>我们的该网络可以通过增加网络层数，引入残差连接、shuffle连接等方式优化模型，增强网络的泛化能力。此外，还可以使用自适应学习率、正则化等技术，进一步优化网络参数。</p>
<p>4.<strong>数据来源新颖</strong>：传统的基于图像的细菌分类方法需要基于显微镜下的图像进行分析和识别。而利用细菌拉曼光谱，则是通过非接触方式直接获取细菌组织的光谱数据，避免了细菌的处理过程对样本造成的影响和污染，同时提供了更加全局、多层次的细菌信息。</p>
<p>5.<strong>数据处理方式创新</strong>：细菌拉曼光谱数据与图像数据不同，需要考虑光谱数据的高维度、数据噪声等问题。基于此，我们运用RamanSpectra库对数据进行预处理和降维，提取有用的特征信息，有利于构建更加高效的分类模型。</p>
<h4 id="部分参考："><a href="#部分参考：" class="headerlink" title="部分参考："></a><strong>部分参考：</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.王吉俐,彭敦陆,陈章,等. AM-CNN:一种基于注意力的卷积神经网络文本分类模型[J]. 小型微型计算机系统,2019,40(4):710-714. DOI:10.3969/j.issn.1000-1220.2019.04.004.</span><br><span class="line"></span><br><span class="line">2.Wang, Linlin, et al. &quot;Relation classification via multi-level attention cnns.&quot; Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2016.</span><br><span class="line"></span><br><span class="line">3.https://mp.weixin.qq.com/s/N-lSzF72TooXAil5FUUW3w</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>深度学习;</tag>
        <tag>自然语言处理;</tag>
      </tags>
  </entry>
</search>
