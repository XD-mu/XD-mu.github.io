<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>torch.manual seed(3407) is all you need: On the influence of random seeds in deep learning architectures for computer vision</title>
    <url>/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/</url>
    <content><![CDATA[<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029121727636.png" alt="摘要"></p>
<p>​	最近阅读到这篇论文，对于里面的调种子的方法比较感兴趣，简单记录一下阅读过程中的一些发现以及一些思考。</p>
<p>​	首先先说结论：<strong>即使方差不是很大，也很容易找到一个比平均值表现好得多或差得多的异常值</strong>。这意味着如果计算量充足并且研究者对于自己的研究足够负责，那么最好探究一下因为随机种子设置、数据集划分等随即来源对于实验结果的影响，最终通过类似平均值、均值、方差、标准差、最值等数据形式展现。</p>
<span id="more"></span>

<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>​	这是一篇论述通过设置torch.manual seed(3407)随机种子对于模型最终结果影响的实验性文章，作者通过大量实验选择出来一类可以影响模型精度的种子。在CIFAR10数据集上，作者探究了一万多个随机种子，同时也利用预训练模型在ImageNet大数据集上进行实验。</p>
<p>​	整篇文章围绕着这三个问题展开的：</p>
<ol>
<li>随机种子的不同导致的模型结果分布是怎样的?</li>
<li>是否存在黑天鹅事件，也就是存在效果明显不同的随机种子？</li>
<li>在更大的数据集上进行预训练是否可以减少由选择种子引起的差异性？</li>
</ol>
<h2 id="实验设置"><a href="#实验设置" class="headerlink" title="实验设置"></a>实验设置</h2><p>​	由于这只是一个简单的实验，并不是想要得到模型最好的结果，因此作者仅尝试在V100 GPU上进行实验，GPU时间限制为1000小时。（作为实验来讲，算力还是很充足的😄）</p>
<p>​	<font color=Red><strong>CIFAR 10</strong></font>: 在CIFAR 10数据集上，作者选取了10000个随机种子，每个随机种子利用30s的时间来训练和测试，总耗时将近83h。模型架构采用的是9层ResNet，优化器是SGD。为了保证部分实验中，模型是接近收敛的，因此作者对其中500次的结果训练时长延迟至1分钟。最后，总算力消耗为90h的V100 GPU运行时间。</p>
<p>​	<font color=Red><strong>ImageNet</strong></font>: 在ImageNet大型数据集上难以快速进行实验，因此作者使用预训练好的网络，然后仅仅对于最后一层分类层进行初始化并从头训练。每次实验模型训练时间为2h，测试50s。最终总耗时440h的V100 GPU运行时间。</p>
<p>​	<font color=Red>实验缺陷</font>: </p>
<p>​	作者通过实验表面，以上这种实验设置存在如下缺陷：</p>
<ol>
<li>实验中，模型结果并不是SOTA（由于运行时间限制导致，可能训练时间进一步增加可以得到更好的结果）</li>
<li>在ImageNet数据集上，作者使用的是预训练模型，仅对最后一层网络进行训练，所以最终的结果只能说明与最后一层的训练和优化有关（而不是整个模型）。</li>
</ol>
<h2 id="问题解决"><a href="#问题解决" class="headerlink" title="问题解决"></a>问题解决</h2><h3 id="1、随机种子的不同导致的模型结果分布是怎样的"><a href="#1、随机种子的不同导致的模型结果分布是怎样的" class="headerlink" title="1、随机种子的不同导致的模型结果分布是怎样的?"></a>1、随机种子的不同导致的模型结果分布是怎样的?</h3><p>​	针对第一个问题，作者首先在CIFAR 10上对500个不同的种子进行训练，得到如下结果图:（视线为均值，深红色区域对应一个标准差，浅红色对应最大值和最小值）</p>
<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029125231600.png" alt="Resnet9架构在CIFAR 10上的验证精度随训练历元数的变化，实线表示超过500个种子的平均值，深红色区域对应一个标准差，浅红色对应最大值和最小值。"></p>
<p><strong>作者发现：</strong></p>
<p>​	1. 模型在25个epoch后准确率就不增加了，说明训练收敛了。然而，准确率的标准差并没有收敛（红色区域并没有变小），说明训练更久不会减少随机种子带来的差异。</p>
<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029125306052.png" alt="在CIFAR 10上对超过500粒种子的Resnet9架构进行最终验证精度的直方图和密度图。底部的每一个破折号对应一次epoch。"></p>
<ol start="2">
<li>模型准确率大多集中在90.5%至90.1%左右，也就是说，如果不去刻意选取特别好或者特别差的随机种子的话，不同随机种子带来的准确率差异普遍为0.5%。(结果图中底部的每个破折号对应一次跑动)</li>
</ol>
<p>​	因此，回到第一个问题，<font color=Red><strong>随机种子的不同导致的模型效果分布是怎样的？</strong> </font>答案显然就是：不同随机种子的运行效果分布是<strong>相当集中</strong>的——这是一个比较令人满意的结果，除非有人刻意去“调”随机种子，不然最后的结果是能够比较反应模型效果的。</p>
<h3 id="2、是否存在“黑天鹅事件”？"><a href="#2、是否存在“黑天鹅事件”？" class="headerlink" title="2、是否存在“黑天鹅事件”？"></a>2、是否存在“黑天鹅事件”？</h3><p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029123748289.png" alt="CIFAR 10数据集上，不同随机种子在较长和较短训练时间下的结果"></p>
<p><strong>作者发现：</strong></p>
<ol>
<li>模型训练长比训练时间短效果更好。此外，在短训练时间条件下，准确率最小值和最大值相差为1.82%。（可以说在深度学习领域里差距比较大了）</li>
<li>10000个随机种子的结果发现，准确率主要位于89.5%至90.5%的区间中。如果不扫描大量的种子，就不可能获得更高或更低的极端值。话虽如此，仅通过扫描前10000个随机种子得到的极值并不能代表该模型正常的结果。</li>
</ol>
<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029125429893.png" alt="CIFAR 10 数据集上10000个随机种子的结果"></p>
<p>​	因此，回到问题二：是否存在黑天鹅事件？显然，黑天鹅是存在的。确实有种子表现得比较好或者比较差，这是一个比较令人担忧的结果，<font color=Red><strong>因为当前深度学习社区内，大多文章都是追求模型效果的，而这种较好的效果可能仅仅是由于随机种子引起的</strong>。</font></p>
<h3 id="3、在更大的数据集上进行预训练是否可以减少由选择种子引起的差异性？"><a href="#3、在更大的数据集上进行预训练是否可以减少由选择种子引起的差异性？" class="headerlink" title="3、在更大的数据集上进行预训练是否可以减少由选择种子引起的差异性？"></a>3、在更大的数据集上进行预训练是否可以减少由选择种子引起的差异性？</h3><p>​	为了验证大规模数据集对于种子造成模型精度的差异性，作者接着在ImageNet数据集进行实验，得到了如下结果：<br><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029124242124.png" alt="ImageNet数据集上不同模型不同随机种子的准确率"></p>
<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029125456844.png" alt="预训练好的ResNet50网络在Imagenet上最终验证精度的直方图和密度图。底部的每个破折号对应一次跑动。"></p>
<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029125531691.png" alt="自监督预训练的Visual Transformer在Imagenet上的最终验证精度的直方图和密度图。底部的每个破折号对应一次跑动"></p>
<p><strong>作者发现：</strong></p>
<ol>
<li>大数据集的上的结果标准差是比CIFA 10<strong>小得多</strong>的，根据上表还是能够观察到大约0.5%的结果提升——这仅仅是由于随机种子引起的。然而，0.5%的准确率提高在CV领域已经可以算是很明显的提升了。</li>
<li>ImageNet数据集上的结果与CIFAR 10的分布还是有比较大的差异——这是由于随机种子仅仅选了50个的原因。然而，作者认为，哪怕是测试更多的随机种子，准确率分布的差异也不会达到1%以上。</li>
</ol>
<p><img src="/2023/10/29/torch-manual-seed-3407-is-all-you-need-On-the-influence-of-random-seeds-in-deep-learning-architectures-for-computer-vision/image-20231029125623204.png" alt="自监督预训练的ResNet50网络在Imagenet上的最终验证精度的直方图和密度图"></p>
<h3 id="3、在更大的数据集上进行预训练是否能减少由选择种子引起的差异性"><a href="#3、在更大的数据集上进行预训练是否能减少由选择种子引起的差异性" class="headerlink" title="3、在更大的数据集上进行预训练是否能减少由选择种子引起的差异性?"></a>3、<strong>在更大的数据集上进行预训练是否能减少由选择种子引起的差异性?</strong></h3><p>​	原文作者写到：<strong>它确实减少了因使用不同种子而产生的变异，但它并不能减轻这种变异。在Imagenet上，我们发现最大和最小精度之间的差异约为0.5 %，这通常被社区认为是该数据集的显著性。</strong>说白了，这个并不是一个符合作者预期的结果，因为目前预训练模型在CV领域里是广泛使用的，哪怕是用的同一个预训练模型，只要你扫描50个随机种子进行测试，你还是能够得到比较好的结果。</p>
<h3 id="思考"><a href="#思考" class="headerlink" title="思考"></a>思考</h3><p>​	下次做实验时设置这个可能会提升代码模型的精确度😎😎😎</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.manual_seed(<span class="number">3407</span>)</span><br></pre></td></tr></table></figure>

<p>​	论文地址：<a href="https://arxiv.org/abs/2109.08203">https://arxiv.org/abs/2109.08203</a></p>
]]></content>
      <categories>
        <category>学习</category>
        <category>论文精读</category>
      </categories>
      <tags>
        <tag>计算机视觉;</tag>
        <tag>深度学习;</tag>
        <tag>Tricks;</tag>
      </tags>
  </entry>
  <entry>
    <title>基于AM-CNN的细菌图谱分类模型</title>
    <url>/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/</url>
    <content><![CDATA[<h1 id="1-实现过程"><a href="#1-实现过程" class="headerlink" title="1.实现过程"></a>1.实现过程</h1><h2 id="1-1模型选择"><a href="#1-1模型选择" class="headerlink" title="1.1模型选择"></a>1.1模型选择</h2><h3 id="1-1-1基于注意力改进的卷积神经网络算法（AM-CNN）"><a href="#1-1-1基于注意力改进的卷积神经网络算法（AM-CNN）" class="headerlink" title="1.1.1基于注意力改进的卷积神经网络算法（AM-CNN）"></a>1.1.1基于注意力改进的卷积神经网络算法（AM-CNN）</h3><p>​	<font color=Red><strong>AM-CNN</strong></font></p>
<p>​	AM-CNN（基于注意力改进的卷积神经网络）模型是一种用于处理细菌拉曼图谱数据的新型深度学习算法。该模型在输入数据特征组合时，考虑了细菌拉曼图谱的波长向量和强度向量，通过滑动窗口方式获取目标词与周围词的综合向量。首先，通过第一次的注意力机制捕获实体与序列中每个词的相关性，并将其与输入的综合词向量矩阵相乘。接着，对卷积结果使用第二次注意力机制捕获视窗与关系的相关性。最终，将卷积结果与相关性矩阵相乘，得到最后的输出结果。</p>
<span id="more"></span>

<p>​	（这个模型的核心在于将细菌拉曼图谱的波长向量和强度向量与输入数据进行组合。首先，将这两种向量进行拼接，构成了最初的输入向量。接着，使用滑动窗口的方式将目标词与周围词组合在一起，形成综合向量。第一次的注意力机制应用在实体与序列中每个词的相关性。将相关性矩阵与输入的综合词向量矩阵相乘，得到一个二维矩阵。然后，使用卷积提取特征，并对卷积结果使用第二次注意力机制捕获视窗与关系的相关性。最后，将卷积结果与相关性矩阵相乘，得到最终的输出结果。通过这种方式，模型能够充分考虑细菌拉曼图谱的波长向量和强度向量在输入数据中的关联关系。）</p>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/image-20230801094141414.png" alt="image-20230801094141414"></p>
<p>​																			模型结构</p>
<p>网络构建：</p>
<ol>
<li>输入层：将细菌拉曼图谱的波长向量和强度向量作为输入数据。波长向量和强度向量可以分别作为两个输入通道。</li>
<li>注意力机制1：使用注意力机制1捕获输入数据中实体与序列中每个词的相关性。可以采用自注意力（self-attention）机制或全局平均池化（global average pooling）等方式。</li>
<li>综合词向量矩阵：将注意力机制1得到的相关性矩阵与输入的综合词向量矩阵相乘，得到一个二维矩阵，用于提取特征。</li>
<li>卷积层：使用卷积层对综合词向量矩阵进行特征提取，可以使用不同的卷积核大小和数量，以捕获不同尺度的特征。</li>
<li>注意力机制2：使用注意力机制2对卷积结果进行进一步的特征选择，捕获视窗与关系的相关性。</li>
<li>全连接层：将经过注意力机制2的卷积结果展平，并通过全连接层进行特征融合和映射，得到最终的输出。</li>
<li>输出层：根据任务需求，可以添加合适的输出层，如softmax层用于分类任务，sigmoid层用于二分类任务等。</li>
<li>损失函数：选择合适的损失函数用于模型的训练和优化。</li>
</ol>
<p>​	</p>
<p>​	我们在训练网络时，为了使得模型可以更快更准确的训练，加入了学习率的自适应调整函数，可以根据训练的数据情况以及已有的训练量来自动调整学习率，使训练效果达到最优。</p>
<p>具体模型构架如下：	</p>
<ol>
<li>我们首先将训练数据集按照4：1划分成训练集与验证集。</li>
<li>构建AM-CNN网络框架</li>
<li>将训练数据输入AM-CNN网络进行1000轮训练</li>
<li>待模型训练好后，使用测试数据测试模型预测结果</li>
<li>调整模型参数，待模型结构最优后，测试模型最终的分类准确度，并记录训练期间 Loss 值的变动情况。</li>
</ol>
<h2 id="1-2基于注意力改进的卷积神经网络（AM-CNN）实验结果"><a href="#1-2基于注意力改进的卷积神经网络（AM-CNN）实验结果" class="headerlink" title="1.2基于注意力改进的卷积神经网络（AM-CNN）实验结果"></a>1.2基于注意力改进的卷积神经网络（AM-CNN）实验结果</h2><p>训练结束后，本实验分别随机选取了3种细菌的50个拉曼数据进行模型评估。</p>
<h3 id="1-2-1未标注数据混合"><a href="#1-2-1未标注数据混合" class="headerlink" title="1.2.1未标注数据混合"></a>1.2.1未标注数据混合</h3><h3 id="1-2-2标注数据混合（6种细菌训练与分类效果）"><a href="#1-2-2标注数据混合（6种细菌训练与分类效果）" class="headerlink" title="1.2.2标注数据混合（6种细菌训练与分类效果）"></a>1.2.2标注数据混合（6种细菌训练与分类效果）</h3><h5 id="1-训练准确率变化情况"><a href="#1-训练准确率变化情况" class="headerlink" title="1.训练准确率变化情况"></a>1.训练准确率变化情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/%E8%AE%AD%E7%BB%83%E5%87%86%E7%A1%AE%E7%8E%87+%E8%AF%84%E4%BC%B0%E5%87%86%E7%A1%AE%E7%8E%87.png" alt="训练准确率+评估准确率"></p>
<p>准确率变化较为理想，满足预期要求!</p>
<ul>
<li>在第38次训练后模型的<strong>训练准确率</strong>维持在98%</li>
<li>在第38次训练后模型的<strong>验证准确率</strong>维持在95%</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">模型验证通常是在训练过程中使用一个独立于训练集和测试集的数据集进行模型性能评估。它可以用来检测模型是否过拟合或者欠拟合。如果模型在训练集上表现良好，但在验证集上表现较差，那就意味着模型可能过拟合了。这种情况下，可以采取一些方法如提前停止训练或增加正则化等来防止模型过拟合。</span><br><span class="line"></span><br><span class="line">训练准确率代表模型在当前训练数据上的表现。训练多轮后，训练准确率会逐渐提高，这表明模型学到了更多的数据分类特征。但是，如果训练准确率开始变得非常高，而验证准确率却不再提高，这说明模型开始过拟合训练数据。</span><br></pre></td></tr></table></figure>

<h5 id="2-训练LOSS值变化情况"><a href="#2-训练LOSS值变化情况" class="headerlink" title="2.训练LOSS值变化情况"></a>2.训练LOSS值变化情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/1LOSS.png" alt="1LOSS"></p>
<h5 id="模型分别对于n种细菌数据各自分类情况"><a href="#模型分别对于n种细菌数据各自分类情况" class="headerlink" title="模型分别对于n种细菌数据各自分类情况"></a>模型分别对于n种细菌数据各自分类情况</h5><p><img src="/2023/10/06/%EF%BF%BD%EF%BF%BDAM-CNN%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD1%06%7B!%EF%BF%BD/98.833%25%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD%06%7B%C5%B5Process.png" alt="98.833%四种细菌分类情况Process"></p>
<p><img src="/2023/10/06/%EF%BF%BD%EF%BF%BDAM-CNN%EF%BF%BD%EF%BF%BD%EF%BF%BD%EF%BF%BD1%06%7B!%EF%BF%BD/98.75%25%06%7B%C5%B5process.png" alt="98.75%分类情况process"></p>
<p><strong>（1）.未标注</strong></p>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/FREE.png" alt="FREE"></p>
<p><strong>（2）.标注</strong></p>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/LABEL.png" alt="LABEL"></p>
<h5 id="5-模型对于测试集的验证情况"><a href="#5-模型对于测试集的验证情况" class="headerlink" title="5.模型对于测试集的验证情况"></a>5.模型对于测试集的验证情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/all_bacteria_heatmap.png" alt="all_bacteria_heatmap"></p>
<h5 id="6-模型六种细菌的ROC变化情况"><a href="#6-模型六种细菌的ROC变化情况" class="headerlink" title="6.模型六种细菌的ROC变化情况"></a>6.模型六种细菌的ROC变化情况</h5><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/ROC.png" alt="ROC"></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ROC曲线可以帮助我们了解分类器在不同阈值下的表现情况，以及在不同的分类阈值下分类器的敏感性和特异性。曲线的横坐标是假正率（False Positive Rate）即被错误地分为正类的样本占所有负样本的比例，曲线的纵坐标是真正率（True Positive Rate）即被正确地分为正类的样本占所有正样本的比例，曲线越接近左上角，说明分类器的表现越好。    通过ROC曲线我们可以判断分类器的性能是否足够好，同时也可以比较多个分类器的性能，选出最佳的分类器。    举个例子如果ROC曲线下的面积（AUC）接近于1，则说明分类器的性能较好，如果ROC曲线下的面积接近于0.5，则说明分类器的性能不如随机猜测（随机猜测的AUC为0.5）。</span><br></pre></td></tr></table></figure>

<p><img src="C:/Users/m/Desktop/新建文件夹/PR.png" alt="PR"></p>
<h3 id="1-2-3与经典网络相比的准确率提升程度"><a href="#1-2-3与经典网络相比的准确率提升程度" class="headerlink" title="1.2.3与经典网络相比的准确率提升程度"></a>1.2.3与经典网络相比的准确率提升程度</h3><p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/compare-169657254906614.png" alt="compare"></p>
<table>
<thead>
<tr>
<th>Method</th>
<th>未标注</th>
<th>标注</th>
</tr>
</thead>
<tbody><tr>
<td>ITQ</td>
<td>0.615</td>
<td>0.628</td>
</tr>
<tr>
<td>SH</td>
<td>0.684</td>
<td>0.744</td>
</tr>
<tr>
<td>DSH</td>
<td>0.765</td>
<td>0.780</td>
</tr>
<tr>
<td>SpH</td>
<td>0.795</td>
<td>0.815</td>
</tr>
<tr>
<td>BGAN</td>
<td>0.847</td>
<td>0.913</td>
</tr>
<tr>
<td>AM-CNN</td>
<td>0.954</td>
<td>0.978</td>
</tr>
</tbody></table>
<p><img src="/2023/10/06/%E5%9F%BA%E4%BA%8EAM-CNN%E7%9A%84%E7%BB%86%E8%8F%8C%E5%9B%BE%E8%B0%B1%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/performence-169657256481017.png" alt="performence"></p>
<h2 id="2-创新点"><a href="#2-创新点" class="headerlink" title="2.创新点"></a>2.创新点</h2><p>关于基于细菌拉曼光谱和注意力机制的CNN网络的创新性内容，具有以下几个主要优势：</p>
<p>1.<strong>引入注意力机制</strong>：</p>
<p>传统的卷积神经网络在图像分类任务中，通常使用池化层、全局卷积核等方式提取图像特征。而引入了注意力机制之后，可以使网络更加关注细菌图像的重要特征，从而提高分类精度。</p>
<p>注意力机制在网络中加入一个注意力模块，用于选择和强调输入光谱数据中的重要信息。在该网络中，注意力机制可以结合不同的损失函数进行优化，从而使网络更加有效地学习到重要特征，提高分类的效果。</p>
<p>2.<strong>应用自适应阈值策略</strong>：</p>
<p>传统的细菌分类算法基于训练集的特征设定分类阈值，在测试集上运用时分类效果可能会有所下降。而基于细菌拉曼光谱和注意力机制的CNN网络，可以采用自适应阈值策略，实现对数据特征的自适应调整，避免了传统算法阈值设定不准确的问题。</p>
<p>该网络中引入自适应阈值参数，在网络训练时动态更新自适应阈值<strong>参数</strong>，通过不断的反馈训练数据的特征，不断地调整自适应阈值参数，避免了传统算法阈值设定不准确的问题。</p>
<p>3.<strong>优化模型参数：</strong></p>
<p>优化模型参数可以提高网络的训练速度和泛化能力，进而提高分类精度。在基于细菌拉曼光谱和注意力机制的CNN网络中，可以通过改变层数、添加跨层连接等方式优化模型的参数，提高分类的效果。</p>
<p>我们的该网络可以通过增加网络层数，引入残差连接、shuffle连接等方式优化模型，增强网络的泛化能力。此外，还可以使用自适应学习率、正则化等技术，进一步优化网络参数。</p>
<p>4.<strong>数据来源新颖</strong>：传统的基于图像的细菌分类方法需要基于显微镜下的图像进行分析和识别。而利用细菌拉曼光谱，则是通过非接触方式直接获取细菌组织的光谱数据，避免了细菌的处理过程对样本造成的影响和污染，同时提供了更加全局、多层次的细菌信息。</p>
<p>5.<strong>数据处理方式创新</strong>：细菌拉曼光谱数据与图像数据不同，需要考虑光谱数据的高维度、数据噪声等问题。基于此，我们运用RamanSpectra库对数据进行预处理和降维，提取有用的特征信息，有利于构建更加高效的分类模型。</p>
<h4 id="部分参考："><a href="#部分参考：" class="headerlink" title="部分参考："></a><strong>部分参考：</strong></h4><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.王吉俐,彭敦陆,陈章,等. AM-CNN:一种基于注意力的卷积神经网络文本分类模型[J]. 小型微型计算机系统,2019,40(4):710-714. DOI:10.3969/j.issn.1000-1220.2019.04.004.</span><br><span class="line"></span><br><span class="line">2.Wang, Linlin, et al. &quot;Relation classification via multi-level attention cnns.&quot; Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 2016.</span><br><span class="line"></span><br><span class="line">3.https://mp.weixin.qq.com/s/N-lSzF72TooXAil5FUUW3w</span><br></pre></td></tr></table></figure>

<h2 id="2-模型部署"><a href="#2-模型部署" class="headerlink" title="2.模型部署"></a>2.模型部署</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> matplotlib.font_manager <span class="keyword">import</span> FontProperties</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> pretty_confusion_matrix <span class="keyword">import</span> pp_matrix_from_data</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> roc_curve, auc</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> cycle</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> precision_recall_curve, average_precision_score</span><br><span class="line"><span class="comment">#字体路径</span></span><br><span class="line"><span class="comment"># font = FontProperties(fname=&#x27;./font/songti.ttf&#x27;, size=12)</span></span><br><span class="line"><span class="comment"># plt.rcParams[&#x27;font.sans-serif&#x27;] = [font.get_name()]</span></span><br><span class="line"><span class="comment"># plt.rcParams[&#x27;axes.unicode_minus&#x27;] = False</span></span><br><span class="line"></span><br><span class="line">os.environ[<span class="string">&#x27;TF_ENABLE_ONEDNN_OPTS&#x27;</span>] = <span class="string">&#x27;0&#x27;</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"><span class="comment">#支持中文</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line"><span class="comment"># 设置文件夹目录</span></span><br><span class="line">train_dir = <span class="string">&#x27;./Final_Data_Ori/train&#x27;</span>  <span class="comment"># 训练数据文件夹</span></span><br><span class="line">test_dir = <span class="string">&#x27;./Final_Data_Ori/test&#x27;</span>  <span class="comment"># 测试数据文件夹</span></span><br><span class="line">model_dir = <span class="string">&#x27;./model&#x27;</span>  <span class="comment"># 模型保存文件夹</span></span><br><span class="line">batch_size=<span class="number">1</span></span><br><span class="line"><span class="comment">#自动获取所有的细菌标签</span></span><br><span class="line">origin_folder_path=<span class="string">&#x27;./Origin_Data/data2&#x27;</span></span><br><span class="line">labels=[]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载测试数据函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_data</span>(<span class="params">data_dir</span>):</span><br><span class="line">    X = []</span><br><span class="line">    y = []</span><br><span class="line">    <span class="keyword">for</span> filename <span class="keyword">in</span> os.listdir(data_dir):</span><br><span class="line">        <span class="keyword">if</span> filename.endswith(<span class="string">&quot;.txt&quot;</span>):</span><br><span class="line">            file_path = os.path.join(data_dir, filename)</span><br><span class="line">            data = np.loadtxt(file_path)</span><br><span class="line">            <span class="keyword">if</span> data.ndim &lt; <span class="number">2</span>:</span><br><span class="line">                data = np.expand_dims(data, axis=<span class="number">0</span>)</span><br><span class="line">            X.append(data)</span><br><span class="line">            label = filename.split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">            y.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(X), np.array(y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 遍历标签目录</span></span><br><span class="line"><span class="keyword">for</span> root, dirs, files <span class="keyword">in</span> os.walk(origin_folder_path):</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">dir</span> <span class="keyword">in</span> dirs:</span><br><span class="line">        <span class="comment"># 将文件夹名称添加到标签列表中</span></span><br><span class="line">        labels.append(<span class="built_in">dir</span>)</span><br><span class="line">labels = [label <span class="keyword">for</span> label <span class="keyword">in</span> labels <span class="keyword">if</span> label != <span class="string">&#x27;.ipynb_checkpoints&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span>(labels)</span><br><span class="line"></span><br><span class="line">X_train, y_train = load_data(train_dir)</span><br><span class="line">X_test, y_test = load_data(test_dir)</span><br><span class="line"><span class="comment">#############################</span></span><br><span class="line"><span class="comment"># 将标签编码为整数</span></span><br><span class="line">unique_labels = np.unique(y_train)</span><br><span class="line">label_dict = &#123;label: i <span class="keyword">for</span> i, label <span class="keyword">in</span> <span class="built_in">enumerate</span>(unique_labels)&#125;</span><br><span class="line">y_train = np.array([label_dict[label] <span class="keyword">for</span> label <span class="keyword">in</span> y_train])</span><br><span class="line">y_test = np.array([label_dict[label] <span class="keyword">for</span> label <span class="keyword">in</span> y_test])</span><br><span class="line">num_classes = <span class="built_in">len</span>(unique_labels)</span><br><span class="line"><span class="comment"># 划分训练集和验证集</span></span><br><span class="line">X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=<span class="number">0.2</span>, random_state=<span class="number">42</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载模型85%model.h5</span></span><br><span class="line"><span class="comment"># best_model_path = os.path.join(model_dir, &#x27;best_model.h5&#x27;)</span></span><br><span class="line">best_model_path = os.path.join(model_dir, <span class="string">&#x27;96%.h5&#x27;</span>)</span><br><span class="line">model = load_model(best_model_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行预测</span></span><br><span class="line">y_pred = model.predict(X_test)</span><br><span class="line">y_pred_classes = np.argmax(y_pred, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">loss, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Loss:&quot;</span>, loss)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Accuracy:&quot;</span>, accuracy)</span><br><span class="line"></span><br><span class="line">cmap = <span class="string">&quot;PuRd&quot;</span></span><br><span class="line">pp_matrix_from_data(y_test, y_pred_classes,columns=labels,lw=accuracy,cmap=cmap)</span><br><span class="line"><span class="built_in">print</span>(y_test)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;----------------------------------------&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(y_pred_classes)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;----------------------------------------&#x27;</span>)</span><br><span class="line"><span class="comment"># print(labels)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;----------------------------------------&#x27;</span>)</span><br><span class="line"><span class="comment">##########ROC曲线##############</span></span><br><span class="line"><span class="comment"># 画ROC曲线</span></span><br><span class="line"><span class="comment"># 分别绘制每个类别的ROC曲线</span></span><br><span class="line">fpr = <span class="built_in">dict</span>()</span><br><span class="line">tpr = <span class="built_in">dict</span>()</span><br><span class="line">roc_auc = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">    fpr[i], tpr[i], _ = roc_curve(y_test==i, y_pred[:, i])</span><br><span class="line">    roc_auc[i] = auc(fpr[i], tpr[i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加颜色和标签</span></span><br><span class="line">colors = cycle([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;k&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(num_classes), colors):</span><br><span class="line">    plt.plot(fpr[i], tpr[i], color=color, lw=<span class="number">2</span>,</span><br><span class="line">             label=<span class="string">&#x27;ROC curve of &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span></span><br><span class="line">             <span class="string">&#x27;&#x27;</span>.<span class="built_in">format</span>(labels[i], roc_auc[i]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一些ROC指令</span></span><br><span class="line">plt.plot([<span class="number">0</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">1</span>], <span class="string">&#x27;k--&#x27;</span>, lw=<span class="number">2</span>)</span><br><span class="line">plt.xlim([-<span class="number">0.05</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;False Positive Rate&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;True Positive Rate&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;ROC Curves&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个类别的平均精度分数</span></span><br><span class="line">average_precision = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">    average_precision[i] = average_precision_score(y_test == i, y_pred[:, i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算每个类别的精度-召回率曲线</span></span><br><span class="line">precision = <span class="built_in">dict</span>()</span><br><span class="line">recall = <span class="built_in">dict</span>()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">    precision[i], recall[i], _ = precision_recall_curve(y_test == i, y_pred[:, i])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制每个类别的精度-召回率曲线</span></span><br><span class="line">colors = cycle([<span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>, <span class="string">&#x27;k&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i, color <span class="keyword">in</span> <span class="built_in">zip</span>(<span class="built_in">range</span>(num_classes), colors):</span><br><span class="line">    plt.plot(recall[i], precision[i], color=color, lw=<span class="number">2</span>,</span><br><span class="line">             label=<span class="string">&#x27;Precision-Recall curve of &#123;0&#125; (area = &#123;1:0.2f&#125;)&#x27;</span></span><br><span class="line">             <span class="string">&#x27;&#x27;</span>.<span class="built_in">format</span>(labels[i], average_precision[i]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加一些PR曲线指令</span></span><br><span class="line">plt.xlim([<span class="number">0.0</span>, <span class="number">1.0</span>])</span><br><span class="line">plt.ylim([<span class="number">0.0</span>, <span class="number">1.05</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;Recall&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Precision&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;Precision-Recall Curves&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&quot;lower right&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>学习</category>
        <category>课外项目</category>
      </categories>
      <tags>
        <tag>深度学习;</tag>
        <tag>自然语言处理;</tag>
      </tags>
  </entry>
</search>
